{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97dc822c-32a3-4662-b7c7-c28b13d61696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import necessary Libraries\n",
    "import os\n",
    "import re\n",
    "import rasterio\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from numpy import array\n",
    "from shapely.geometry import shape\n",
    "from rasterio.windows import Window, from_bounds\n",
    "from rasterio.mask import mask\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bb7660f-01e3-4f32-b746-a5c8401f16e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input TIFF file path\n",
    "input_tiff =\"1.Dataset/Enschede/Inference/ENS_RGB_008.tif\"\n",
    "\n",
    "# Define the input shapefile Bbox path\n",
    "input_bbox = \"1.Dataset/Enschede/Inference/Outlines_Buildings_Buffer2m.shp\"\n",
    "\n",
    "# Define the input shapefile innerplanes path\n",
    "input_planes = \"1.Dataset/Enschede/Inference/Inner_Buildings_Planes.shp\"\n",
    "\n",
    "# Define the output folder path\n",
    "output_folder = \"2.TrainingPreparation/EnschedeInference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09f5a380-6af6-4ec8-9949-4c517a3c8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder+\"/npy\")\n",
    "    os.mkdir(output_folder+\"/geom_txt\")\n",
    "    os.mkdir(output_folder+\"/clipped\")\n",
    "    os.mkdir(output_folder+\"/rgb\")\n",
    "    os.mkdir(output_folder+\"/inner_planes\")\n",
    "    os.mkdir(output_folder+\"/annot\")\n",
    "    os.mkdir(output_folder+\"/det_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0a9a789-2389-4ae3-8de0-ba31d6d35cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the TIFF file and get its spatial reference\n",
    "ds_tiff = rasterio.open(input_tiff)\n",
    "srs_tiff = ds_tiff.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c09527c1-c480-4240-b964-39914f0c8cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the shapefile and get its spatial reference\n",
    "ds_shp = fiona.open(input_bbox)\n",
    "lyr_shp = ds_shp[0]\n",
    "srs_shp = ds_shp.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93e8ed56-ca2b-4430-9991-2a4e989c3e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polygon_corners(poly):\n",
    "    \"\"\"Extracts the corners of a polygon\"\"\"\n",
    "    coords = list(poly.exterior.coords)\n",
    "    return {coord: [] for coord in coords}\n",
    "\n",
    "def get_corners_and_edges(shapefile_path):\n",
    "    # Read in the shapefile as a GeoDataFrame\n",
    "    gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "    # Extract the corners of each polygon\n",
    "    corners_dict = {}\n",
    "    for i, row in gdf.iterrows():\n",
    "        poly_corners = get_polygon_corners(row.geometry)\n",
    "        corners_dict.update(poly_corners)\n",
    "\n",
    "    # Create edges between adjacent corners\n",
    "    for i, row in gdf.iterrows():\n",
    "        coords = list(row.geometry.exterior.coords)\n",
    "        for i, coord in enumerate(coords):\n",
    "            next_coord = coords[(i + 1) % len(coords)]\n",
    "            if coord != next_coord:\n",
    "                if next_coord not in corners_dict[coord]:\n",
    "                    corners_dict[coord].append(next_coord)\n",
    "                if coord not in corners_dict[next_coord]:\n",
    "                    corners_dict[next_coord].append(coord)\n",
    "\n",
    "    return corners_dict\n",
    "\n",
    "# Define the math operation you want to apply to the coordinates\n",
    "def modify_coords(sbbox, x, y, sz=255):\n",
    "    minx, miny, maxx, maxy = sbbox.total_bounds\n",
    "    new_x = ((sz*(x - minx))/(maxx-minx))\n",
    "    new_y = sz-((sz*(y - miny))/(maxy-miny)) # flip y coordinates to match annotation in HEAT paper\n",
    "    \n",
    "    return (new_x, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5623e275-a733-4a94-899f-bc31fe9c3919",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55e2bd3cdae4724a88db98b44d91ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2465 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the target size\n",
    "sz=300\n",
    "target_size = (sz, sz)\n",
    "\n",
    "# Loop through each feature in the shapefile and clip the TIFF file\n",
    "for feat in tqdm(ds_shp):\n",
    "    base_name = feat['id']\n",
    "    geom = shape(feat['geometry'])\n",
    "    xmin, ymin, xmax, ymax = geom.bounds\n",
    "    ##### CRS AND GEOMETRY\n",
    "    # Save bbox to txt\n",
    "    # print(\"Saving \"+str(base_name))\n",
    "    # print(str(srs_shp) + \"\\n\" + str(xmin)+ str(xmax)+ str(ymin)+ str(ymax))\n",
    "    with open(f\"{output_folder}/geom_txt/{base_name}.txt\", 'w') as f:\n",
    "        f.write(str(srs_shp) + \"\\n\" + str(xmin)+ \",\" + str(xmax)+ \",\" + str(ymin)+ \",\" + str(ymax))\n",
    "    \n",
    "    ##### CLIPPING AND RESIZING IMAGE\n",
    "    # Define the output file name based on the feature ID\n",
    "    clip_tiff = f\"{output_folder}/clipped/{base_name}.tif\"\n",
    "\n",
    "    # print(\"Clipping \"+str(base_name))\n",
    "    # Clip the new raster to the feature polygon\n",
    "    clipped_data = ds_tiff.read(window=from_bounds(xmin, ymin, xmax, ymax, ds_tiff.transform))\n",
    "    window = Window(col_off=xmin, row_off=ymin, width=xmax-xmin, height=ymax-ymin)\n",
    "\n",
    "    # Get the metadata of the original raster\n",
    "    out_meta = ds_tiff.meta.copy()\n",
    "    \n",
    "    # Update the metadata with the new dimensions and transform\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": clipped_data.shape[1],\n",
    "        \"width\": clipped_data.shape[2],\n",
    "        \"transform\": ds_tiff.window_transform(window)\n",
    "    })\n",
    "    with rasterio.open(clip_tiff, \"w\", **out_meta) as dest:\n",
    "        dest.write(clipped_data)\n",
    "    \n",
    "    # Resizing\n",
    "    # print(\"Resizing \"+str(base_name))\n",
    "    # Define the output file name based on the feature ID\n",
    "    resize_tiff = f\"{output_folder}/rgb/{base_name}.jpg\"\n",
    "    with Image.open(clip_tiff) as img:\n",
    "        # Resize the image\n",
    "        resized_img = img.resize(target_size)\n",
    "        # Convert the image to JPEG format\n",
    "        resized_img = resized_img.convert(\"RGB\")\n",
    "\n",
    "        # Save the image in JPEG format\n",
    "        resized_img.save(resize_tiff, \"JPEG\")\n",
    "\n",
    "    ##### INNER PLANES\n",
    "    ### Selecting planes within buffer\n",
    "    # Read in the shapefiles\n",
    "    inner_planes = gpd.read_file(input_planes)\n",
    "    bounding_box = gpd.read_file(input_bbox)\n",
    "    curr_poly = bounding_box[bounding_box['FID1']==int(base_name)]\n",
    "    # Select all polygons that are completely contained within the bounding box\n",
    "    # print(\"Selecting planes \"+str(base_name))\n",
    "    sel_inner_planes = inner_planes[inner_planes.within(curr_poly.loc[int(base_name), 'geometry'])]\n",
    "    # Write the selected polygons to a new shapefile\n",
    "    out_inner_planes = f\"{output_folder}/inner_planes/{base_name}.shp\"\n",
    "    sel_inner_planes.to_file(out_inner_planes)\n",
    "    \n",
    "    ### Outputting graphs to dictionary\n",
    "    # print(\"Getting corners and edges \"+str(base_name))\n",
    "    edges= get_corners_and_edges(out_inner_planes)\n",
    "    newedges = {}\n",
    "    for key, value in edges.items():\n",
    "        x, y = key\n",
    "        new_key = (x, y)\n",
    "        new_value = []\n",
    "        for coord in value:\n",
    "            new_x, new_y = coord\n",
    "            new_value.append((new_x, new_y))\n",
    "        newedges[new_key] = new_value\n",
    "    # print(newedges)\n",
    "    # print(\"Finalizing \"+str(base_name))\n",
    "    output_dict = {}\n",
    "    for key, value in newedges.items():\n",
    "        new_key = modify_coords(curr_poly,*key,(sz-1))\n",
    "        new_v = []\n",
    "             new_v.append(array(modify_coords(curr_poly,*point,(sz-1))))\n",
    "        new_value = new_v\n",
    "        output_dict[new_key] = new_value\n",
    "    # print(\"Exporting NPY \"+str(base_name))\n",
    "    # with open(f\"{output_folder}/npy_1/{base_name}.npy\", 'wb') as f:\n",
    "    #     pickle.dump(output_dict, f)\n",
    "    f_out = f\"{output_folder}/annot/{base_name}.npy\"\n",
    "    np.save(f_out, output_dict)\n",
    "        \n",
    "# Clean up\n",
    "ds_tiff = None\n",
    "ds_shp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b31bbc14-dd32-437d-8309-81c75f1697f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "all_annot = glob.glob(\"2.TrainingPreparation/EnschedeInference/annot/*\")\n",
    "output_folder = \"2.TrainingPreparation/EnschedeInference/det_final\"\n",
    "for i in range(len(all_annot)):\n",
    "    # print(all_annot[i])\n",
    "    base_name = re.split('[/.]',all_annot[i])[4]\n",
    "    annot = np.load(all_annot[i], allow_pickle=True, encoding='bytes').tolist()\n",
    "    annot_list = list(np.around(list(annot.keys()),decimals=1))\n",
    "    swapped_annot_list = []\n",
    "    for x, y in annot_list:\n",
    "        swapped_annot_list.append((y, x))\n",
    "    det_out = f\"{output_folder}/{base_name}.npy\"\n",
    "    np.save(det_out,  swapped_annot_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd063a-38dd-4a4d-82cf-6b0bc4458e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
